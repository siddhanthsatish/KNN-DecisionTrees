from json.tool import main
from mimetypes import init
import math
import numpy as np
import scipy.spatial
from collections import Counter
from collections import OrderedDict
import pandas as pd #for data franes 
import matplotlib.pyplot as plt # for data visualization 
import seaborn as sns # for data visualization
import warnings
warnings.filterwarnings('ignore')
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split

class KNN:

    def __init__(self, k):
        self.k = k

    def dataframe(self, data, labels):
        return pd.read_csv(data, names = labels)
    
    def shuffle(self, data):
        return shuffle(data)

    def train_test_split(self, data):
        X, y = train_test_split(data, test_size=0.2)
        return X,y

    def knn(self, X, y):      
        d = {}
        knn = []
        for test_index, test_row in y.iterrows():
            d = {}
            point1 = np.array([test_row['f1'], test_row['f2'], test_row['f3'], test_row['f4']])
            for train_index, train_row in X.iterrows():
                dist = 0
                point2 = np.array([train_row['f1'], train_row['f2'], train_row['f3'], train_row['f4']])
                dist = scipy.spatial.distance.euclidean(point1, point2)
                d.update({ dist : [ train_row['f1'], train_row['f2'], train_row['f3'], train_row['f4'], train_row['label'] ] }) #make tuple
            count=0
            knearest = []
            for i in sorted(d.keys()):
                if(count<self.k):
                    knearest.append(d[i][4])
                    count+=1
                else:
                    break
            # print((knearest, test_row['label']))
            knn.append((knearest, test_row['label']))
        # print(knn)
        return knn
    

    def accuracy(self, knn):
        count = 0 
        for tup in knn:
            l = tup[0]
            occurence_count = Counter(l)
            s = occurence_count.most_common(1)[0][0]
            if s == tup[1]:
                count+=1
        return count/len(knn)
    
    

            
    
obj = KNN(1)
data = 'iris.csv'
labels= ['f1', 'f2', 'f3', 'f4', 'label']
X, y = obj.train_test_split(obj.shuffle(obj.dataframe(data, labels)))
# print(X.head())
# print(y.head())
list = obj.knn(X, X)
acc = obj.accuracy(list)
print(acc)
count = 1
# time = []
# acclist = []
accd = {}
for i in range(1, 51, 2):
    accd.update( {i: []} )
print(accd)

for i in range(1, 3):
    for j in range(1, 51, 2):
        obj = KNN(j)
        data = 'iris.csv'
        labels= ['f1', 'f2', 'f3', 'f4', 'label']
        X, y = obj.train_test_split(obj.shuffle(obj.dataframe(data, labels)))
        # print(X.head())
        # print(y.head())
        list = obj.knn(X, X)
        acc = obj.accuracy(list)
        accd[j].append(acc)
        count+=1


# accd = {1: [0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9, 1.0, 0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9333333333333333, 0.9, 1.0, 0.9], 3: [0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9666666666666667, 0.8666666666666667, 1.0, 1.0, 0.9, 0.9, 0.9666666666666667, 0.9333333333333333, 1.0, 1.0, 0.9333333333333333, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9333333333333333], 5: [1.0, 0.8666666666666667, 0.9, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0], 7: [0.9666666666666667, 1.0, 0.9666666666666667, 0.9, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667], 9: [0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 1.0, 1.0, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9, 0.9333333333333333, 1.0], 11: [0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9, 0.9, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 1.0, 0.9, 0.9666666666666667, 0.9333333333333333, 0.8666666666666667], 13: [0.9333333333333333, 0.9, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9333333333333333, 1.0, 0.8333333333333334, 0.9, 1.0, 0.9, 1.0, 1.0, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667], 15: [0.9, 0.9333333333333333, 1.0, 1.0, 0.9666666666666667, 0.8666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9, 0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333], 17: [0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9, 0.9666666666666667, 1.0, 0.9, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9333333333333333, 0.9, 0.9333333333333333, 1.0, 1.0, 0.9666666666666667, 1.0, 0.9333333333333333, 0.8666666666666667], 19: [0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 0.9, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9, 1.0, 1.0, 0.8666666666666667, 1.0, 1.0, 1.0], 21: [1.0, 0.9, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 1.0, 0.9333333333333333, 1.0], 23: [1.0, 1.0, 0.9, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 1.0, 0.9, 0.9666666666666667, 1.0, 0.9, 0.9333333333333333, 0.9333333333333333, 1.0, 0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333], 25: [0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 0.8, 0.9666666666666667, 1.0, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667], 27: [1.0, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9666666666666667], 29: [0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 1.0, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 1.0, 0.9333333333333333, 1.0], 31: [0.9666666666666667, 0.9333333333333333, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667], 33: [0.9, 0.8666666666666667, 1.0, 1.0, 0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667], 35: [0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9333333333333333], 37: [1.0, 0.9333333333333333, 1.0, 1.0, 0.9, 1.0, 0.9333333333333333, 0.9, 0.9, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9333333333333333, 1.0, 0.9666666666666667, 1.0, 0.9333333333333333, 0.9666666666666667], 39: [0.9333333333333333, 1.0, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 0.9333333333333333, 0.9, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 1.0, 1.0], 41: [0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 1.0, 1.0, 0.9, 0.9666666666666667, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9, 0.9333333333333333, 0.9333333333333333, 0.9, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0], 43: [0.9333333333333333, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9, 0.9, 0.9666666666666667, 0.9666666666666667, 0.9, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333], 45: [0.9, 1.0, 0.9333333333333333, 1.0, 0.9333333333333333, 1.0, 1.0, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 0.9, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 1.0, 1.0, 0.8666666666666667, 0.9333333333333333], 47: [0.9666666666666667, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9, 0.9666666666666667, 1.0, 0.9, 0.9333333333333333, 0.9666666666666667], 49: [0.9666666666666667, 1.0, 1.0, 0.9, 1.0, 0.9, 1.0, 0.9666666666666667, 1.0, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 1.0, 1.0, 0.9333333333333333, 1.0, 0.9666666666666667]}
print(accd)

# plt.plot(time, acclist)
# plt.show()
time = []
accs = []
c = 1

for i in accd:
    accs.append(sum(accd[i])/len(accd[i]))
    time.append(c)
    c+=2

plt.plot(time, accs)
plt.show()












            




    
   